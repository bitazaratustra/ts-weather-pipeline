{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a6772e8-f710-480f-a40d-358c8a137f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados desde archivo CSV\n",
      "Datos: (49920, 4)\n",
      "Datos después de preprocesamiento: (49752, 20)\n",
      "Train: 34826, Validation: 7462, Test: 7464\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/temperature_scaler.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 82\u001b[0m\n\u001b[1;32m     78\u001b[0m test_scaled \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(scaler\u001b[38;5;241m.\u001b[39mtransform(test_df[features]), \n\u001b[1;32m     79\u001b[0m                           columns\u001b[38;5;241m=\u001b[39mfeatures, index\u001b[38;5;241m=\u001b[39mtest_df\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Guardar scaler\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/temperature_scaler.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/temperature_features.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     84\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m: features, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m: target}, f)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.18/envs/ts_weather/lib/python3.9/site-packages/joblib/numpy_pickle.py:599\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(value, filename, compress, protocol)\u001b[0m\n\u001b[1;32m    597\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[0;32m--> 599\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    600\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/temperature_scaler.pkl'"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Predicción de Temperatura\n",
    "# \n",
    "# Este notebook entrena y evalúa modelos para predecir temperatura.\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Importar funciones del pipeline\n",
    "from ts_weather_pipeline.api import fetch_open_meteo_archive\n",
    "from ts_weather_pipeline.preprocessing import fill_and_resample, add_time_features, add_lags, add_fourier\n",
    "from ts_weather_pipeline.baselines import naive_forecast, fit_var, fit_arima\n",
    "from ts_weather_pipeline.deep_learning import make_supervised, build_lstm_model, build_transformer_encoder\n",
    "from ts_weather_pipeline.evaluation import evaluate_multi_horizon\n",
    "from ts_weather_pipeline.transformer import make_supervised_transformer\n",
    "\n",
    "# Configuración\n",
    "target = \"temperature_2m\"\n",
    "plt.style.use('default')\n",
    "\n",
    "# %%\n",
    "# Cargar datos\n",
    "try:\n",
    "    df = pd.read_csv('../data/temperature_data.csv', index_col=0, parse_dates=True)\n",
    "    print(\"Datos cargados desde archivo CSV\")\n",
    "except:\n",
    "    print(\"Descargando datos...\")\n",
    "    df = fetch_open_meteo_archive(\n",
    "        lat=-34.6037, \n",
    "        lon=-58.3816, \n",
    "        start_date=\"2020-01-01\",\n",
    "        end_date=\"2025-09-10\",\n",
    "        hourly_vars=[\"temperature_2m\", \"relativehumidity_2m\", \"windspeed_10m\", \"precipitation\"]\n",
    "    )\n",
    "    df = fill_and_resample(df, freq=\"H\")\n",
    "\n",
    "print(f\"Datos: {df.shape}\")\n",
    "\n",
    "# %%\n",
    "# Añadir características\n",
    "df = add_time_features(df)\n",
    "df = add_lags(df, target, lags=(1, 24, 168))  # 1h, 24h, 1 semana\n",
    "df = add_fourier(df, period_hours=24, n_harmonics=3)\n",
    "\n",
    "# Eliminar valores nulos\n",
    "df = df.dropna()\n",
    "print(f\"Datos después de preprocesamiento: {df.shape}\")\n",
    "\n",
    "# %%\n",
    "# Dividir datos\n",
    "train_size = int(len(df) * 0.7)\n",
    "val_size = int(len(df) * 0.15)\n",
    "test_size = len(df) - train_size - val_size\n",
    "\n",
    "train_df = df.iloc[:train_size]\n",
    "val_df = df.iloc[train_size:train_size+val_size]\n",
    "test_df = df.iloc[train_size+val_size:]\n",
    "\n",
    "print(f\"Train: {train_size}, Validation: {val_size}, Test: {test_size}\")\n",
    "\n",
    "# %%\n",
    "# Escalar datos\n",
    "scaler = MinMaxScaler()\n",
    "features = train_df.select_dtypes(include=\"number\").columns.tolist()\n",
    "scaler.fit(train_df[features])\n",
    "\n",
    "train_scaled = pd.DataFrame(scaler.transform(train_df[features]), \n",
    "                           columns=features, index=train_df.index)\n",
    "val_scaled = pd.DataFrame(scaler.transform(val_df[features]), \n",
    "                         columns=features, index=val_df.index)\n",
    "test_scaled = pd.DataFrame(scaler.transform(test_df[features]), \n",
    "                          columns=features, index=test_df.index)\n",
    "\n",
    "# Guardar scaler\n",
    "joblib.dump(scaler, 'models/temperature_scaler.pkl')\n",
    "with open('models/temperature_features.json', 'w') as f:\n",
    "    json.dump({\"features\": features, \"target\": target}, f)\n",
    "\n",
    "# %%\n",
    "# Preparar datos supervisados\n",
    "input_width = 168  # 1 semana\n",
    "output_width = 24  # 24 horas\n",
    "\n",
    "X_train, y_train, _ = make_supervised(train_scaled, target, input_width, output_width)\n",
    "X_val, y_val, _ = make_supervised(val_scaled, target, input_width, output_width)\n",
    "X_test, y_test, _ = make_supervised(test_scaled, target, input_width, output_width)\n",
    "\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "# %%\n",
    "# Modelo Naive (baseline)\n",
    "naive_pred = naive_forecast(train_df[target], output_width)\n",
    "naive_eval = evaluate_multi_horizon(test_df[target].values[:output_width], naive_pred)\n",
    "\n",
    "print(\"Naive Model Evaluation:\")\n",
    "print(f\"MAE: {naive_eval['mae']:.2f}, RMSE: {naive_eval['rmse']:.2f}, MAPE: {naive_eval['mape']:.2f}%\")\n",
    "\n",
    "# %%\n",
    "# Modelo ARIMA\n",
    "print(\"Entrenando modelo ARIMA...\")\n",
    "try:\n",
    "    exog_feats = [\"hour_sin\", \"hour_cos\", \"month_sin\", \"month_cos\"]\n",
    "    arima_res = fit_arima(train_df[target], exog=train_df[exog_feats])\n",
    "    arima_fc = arima_res.get_forecast(steps=output_width, \n",
    "                                     exog=test_df[exog_feats].iloc[:output_width])\n",
    "    \n",
    "    arima_eval = evaluate_multi_horizon(test_df[target].iloc[:output_width].values, \n",
    "                                       arima_fc.predicted_mean.values)\n",
    "    \n",
    "    print(\"ARIMA Evaluation:\")\n",
    "    print(f\"MAE: {arima_eval['mae']:.2f}, RMSE: {arima_eval['rmse']:.2f}, MAPE: {arima_eval['mape']:.2f}%\")\n",
    "    \n",
    "    # Guardar modelo ARIMA\n",
    "    joblib.dump(arima_res, 'models/arima_temperature_model.pkl')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ARIMA failed: {e}\")\n",
    "\n",
    "# %%\n",
    "# Modelo LSTM\n",
    "print(\"Entrenando modelo LSTM...\")\n",
    "try:\n",
    "    lstm_model = build_lstm_model(\n",
    "        (input_width, len(features)), \n",
    "        output_width, \n",
    "        units=32,  # Reducido para ahorrar memoria\n",
    "        lr=1e-3\n",
    "    )\n",
    "    \n",
    "    history = lstm_model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=20,  # Reducido para ahorrar tiempo\n",
    "        batch_size=32,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluar LSTM\n",
    "    y_pred_lstm = lstm_model.predict(X_test, batch_size=32)\n",
    "    lstm_eval = evaluate_multi_horizon(y_test, y_pred_lstm)\n",
    "    \n",
    "    print(\"LSTM Evaluation:\")\n",
    "    print(f\"MAE: {lstm_eval['mae']:.2f}, RMSE: {lstm_eval['rmse']:.2f}, MAPE: {lstm_eval['mape']:.2f}%\")\n",
    "    \n",
    "    # Guardar modelo LSTM\n",
    "    lstm_model.save('models/lstm_temperature_model.h5')\n",
    "    \n",
    "    # Graficar historial de entrenamiento\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss durante el entrenamiento')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['mean_absolute_error'], label='Training MAE')\n",
    "    plt.plot(history.history['val_mean_absolute_error'], label='Validation MAE')\n",
    "    plt.title('MAE durante el entrenamiento')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"LSTM failed: {e}\")\n",
    "\n",
    "# %%\n",
    "# Modelo Transformer\n",
    "print(\"Entrenando modelo Transformer...\")\n",
    "try:\n",
    "    # Preparar datos para Transformer\n",
    "    X_train_tf, y_train_tf, _ = make_supervised_transformer(train_scaled, target, input_width, output_width)\n",
    "    X_val_tf, y_val_tf, _ = make_supervised_transformer(val_scaled, target, input_width, output_width)\n",
    "    X_test_tf, y_test_tf, _ = make_supervised_transformer(test_scaled, target, input_width, output_width)\n",
    "    \n",
    "    transformer_model = build_transformer_encoder(\n",
    "        (input_width, len(features)),\n",
    "        output_width,\n",
    "        d_model=64,  # Reducido para ahorrar memoria\n",
    "        num_heads=4,\n",
    "        ff_dim=128,\n",
    "        num_blocks=2,\n",
    "        dropout=0.1,\n",
    "        lr=1e-3\n",
    "    )\n",
    "    \n",
    "    history_tf = transformer_model.fit(\n",
    "        X_train_tf, y_train_tf,\n",
    "        validation_data=(X_val_tf, y_val_tf),\n",
    "        epochs=20,  # Reducido para ahorrar tiempo\n",
    "        batch_size=32,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluar Transformer\n",
    "    y_pred_tf = transformer_model.predict(X_test_tf, batch_size=32)\n",
    "    tf_eval = evaluate_multi_horizon(y_test_tf, y_pred_tf)\n",
    "    \n",
    "    print(\"Transformer Evaluation:\")\n",
    "    print(f\"MAE: {tf_eval['mae']:.2f}, RMSE: {tf_eval['rmse']:.2f}, MAPE: {tf_eval['mape']:.2f}%\")\n",
    "    \n",
    "    # Guardar modelo Transformer\n",
    "    transformer_model.save('models/transformer_temperature_model.h5')\n",
    "    \n",
    "    # Graficar historial de entrenamiento\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history_tf.history['loss'], label='Training Loss')\n",
    "    plt.plot(history_tf.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss durante el entrenamiento')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history_tf.history['mean_absolute_error'], label='Training MAE')\n",
    "    plt.plot(history_tf.history['val_mean_absolute_error'], label='Validation MAE')\n",
    "    plt.title('MAE durante el entrenamiento')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Transformer failed: {e}\")\n",
    "\n",
    "# %%\n",
    "# Comparar todos los modelos\n",
    "results = {\n",
    "    'Naive': naive_eval,\n",
    "    'ARIMA': arima_eval if 'arima_eval' in locals() else None,\n",
    "    'LSTM': lstm_eval if 'lstm_eval' in locals() else None,\n",
    "    'Transformer': tf_eval if 'tf_eval' in locals() else None\n",
    "}\n",
    "\n",
    "# Crear gráfico de comparación\n",
    "models = []\n",
    "mae_scores = []\n",
    "rmse_scores = []\n",
    "\n",
    "for model_name, result in results.items():\n",
    "    if result is not None:\n",
    "        models.append(model_name)\n",
    "        mae_scores.append(result['mae'])\n",
    "        rmse_scores.append(result['rmse'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, mae_scores, width, label='MAE')\n",
    "plt.bar(x + width/2, rmse_scores, width, label='RMSE')\n",
    "\n",
    "plt.xlabel('Modelos')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Comparación de Modelos de Predicción de Temperatura')\n",
    "plt.xticks(x, models)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Visualizar predicciones\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Gráfico 1: Naive\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(test_df[target].values[:output_width], label='Real')\n",
    "plt.plot(naive_pred, label='Naive')\n",
    "plt.title('Predicción Naive')\n",
    "plt.legend()\n",
    "\n",
    "# Gráfico 2: ARIMA\n",
    "if 'arima_fc' in locals():\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(test_df[target].values[:output_width], label='Real')\n",
    "    plt.plot(arima_fc.predicted_mean.values, label='ARIMA')\n",
    "    plt.title('Predicción ARIMA')\n",
    "    plt.legend()\n",
    "\n",
    "# Gráfico 3: LSTM\n",
    "if 'y_pred_lstm' in locals():\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(y_test[0], label='Real')\n",
    "    plt.plot(y_pred_lstm[0], label='LSTM')\n",
    "    plt.title('Predicción LSTM')\n",
    "    plt.legend()\n",
    "\n",
    "# Gráfico 4: Transformer\n",
    "if 'y_pred_tf' in locals():\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(y_test_tf[0], label='Real')\n",
    "    plt.plot(y_pred_tf[0], label='Transformer')\n",
    "    plt.title('Predicción Transformer')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Guardar resultados de evaluación\n",
    "evaluation_results = {\n",
    "    'naive': naive_eval,\n",
    "    'arima': arima_eval if 'arima_eval' in locals() else None,\n",
    "    'lstm': lstm_eval if 'lstm_eval' in locals() else None,\n",
    "    'transformer': tf_eval if 'tf_eval' in locals() else None\n",
    "}\n",
    "\n",
    "with open('../models/temperature_evaluation_results.json', 'w') as f:\n",
    "    json.dump(evaluation_results, f, indent=4)\n",
    "\n",
    "print(\"Resultados de evaluación guardados en models/temperature_evaluation_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd26dc-cc3e-4050-a80f-4cf6a35de8af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
